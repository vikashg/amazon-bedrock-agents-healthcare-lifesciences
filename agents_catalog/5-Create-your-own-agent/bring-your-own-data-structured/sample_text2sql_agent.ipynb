{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Text2SQL Agent Walkthrough\n",
    "\n",
    "This notebook will walk users through setting up a generic Text2SQL Agent and run it against the BirdSQL - Mini Dev Dataset (https://github.com/bird-bench/mini_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure the latest version of boto3 is shown below\n",
    "\n",
    "##### If not then run through setup_environment.ipynb in the 0-Notebook-environment/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep \"boto3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in environment variables to notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve import path\n",
    "%store -r IMPORTS_PATH\n",
    "\n",
    "# Retrieve account info\n",
    "%store -r account_id\n",
    "%store -r region\n",
    "\n",
    "# Retrieve model lists\n",
    "%store -r agent_foundation_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve imports environment variable and bring libraries into notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $IMPORTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the variables in os\n",
    "\n",
    "random_suffix_1 = uuid.uuid4().hex[:6]\n",
    "base_bucket_name = f\"{'text2sql-agent'}-{account_id}-{random_suffix_1}\"\n",
    "random_suffix_2 = uuid.uuid4().hex[:6]\n",
    "athena_results_bucket_name = f\"{'text2sql-athena-results'}-{account_id}-{random_suffix_2}\"\n",
    "athena_database_name = 'california_schools'\n",
    "\n",
    "os.environ['REGION'] = region\n",
    "os.environ['BASE_BUCKET_NAME'] = base_bucket_name\n",
    "os.environ['ATHENA_RESULTS_BUCKET_NAME'] = athena_results_bucket_name\n",
    "os.environ['BASE_DIR'] = 'dev_databases'\n",
    "os.environ['DATABASE_NAME'] = athena_database_name\n",
    "\n",
    "%store base_bucket_name\n",
    "%store athena_results_bucket_name\n",
    "%store athena_database_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve BirdSQL - Mini Dev Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download .zip file to local directory\n",
    "\n",
    "!cd 2-Sample-text2sql-agent\n",
    "!wget https://bird-bench.oss-cn-beijing.aliyuncs.com/dev.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Necessary services to run Text2SQL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the Text2SQL agent, we will need to setup the Athena databases to make SQL queries against. The following script will:\n",
    "1. Unzip the downloaded folder\n",
    "2. Create S3 buckets\n",
    "3. Convert .sqlite files into individual .parquet files for each table\n",
    "4. Upload to the database s3 bucket\n",
    "5. Set up appropriate Athena permissions\n",
    "6. Create databases in Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_prep.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Text2SQL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = 'sample-text2sql-agent'\n",
    "agent_description = \"Text2SQL agent to run against Bird-SQL Mini-Dev benchmark dataset\"\n",
    "agent_instruction = \"\"\"\n",
    "You are an AI Agent specialized in generating SQL queries for Amazon Athena against Amazon S3 .parquet files. \n",
    "Your primary task is to interpret user queries, generate appropriate SQL queries, and provide the executed sql \n",
    "query as well as relevant answers based on the data. Follow these instructions carefully: 1. Before generating any \n",
    "SQL query, use the /getschema tool to familiarize yourself with the data structure. 2. When generating an SQL query: \n",
    "a. Write the query as a single line, removing all newline characters. b. Column names must be exactly as they appear \n",
    "in the schema, including spaces. Do not replace spaces with underscores. c. Always enclose column names that contain \n",
    "spaces in double quotes (\"). d. Be extra careful with column names containing special characters or spaces. \n",
    "3. Column name handling: a. Never modify column names. Use them exactly as they appear in the schema. \n",
    "b. If a column name contains spaces or special characters, always enclose it in double quotes (\"). \n",
    "c. Do not use underscores in place of spaces in column names. 4. Query output format: \n",
    "a. Always include the exact query that was run in your response. Start your response with \n",
    "\"Executed SQL Query:\" followed by the exact query that was run. b. Format the SQL query in a code block \n",
    "using three backticks (```). c. After the query, provide your explanation and analysis. \n",
    "5. When providing your response: a. Start with the executed SQL query as specified in step \n",
    "4. b. Double-check that all column names in your generated query match the schema exactly. \n",
    "c. Ask for clarifications from the user if required. 6. Error handling: a. \n",
    "If a query fails due to column name issues: - Review the schema and correct any mismatched column names. - \n",
    "Ensure all column names with spaces are enclosed in double quotes. - Regenerate the query with corrected column names. - \n",
    "Display both the failed query and the corrected query. b. Implement retry logic with up to 3 attempts for failed queries. \n",
    "Here are a few examples of generating SQL queries based on a question: \n",
    "Question: What is the highest eligible free rate for K-12 students in the schools in Alameda County? \n",
    "Executed SQL Query: \"SELECT `Free Meal Count (K-12)` / `Enrollment (K-12)` FROM frpm WHERE `County Name` = 'Alameda' \n",
    "ORDER BY (CAST(`Free Meal Count (K-12)` AS REAL) / `Enrollment (K-12)`) DESC LIMIT 1\" Question: Please list the zip \n",
    "code of all the charter schools in Fresno County Office of Education. Executed SQL Query: \"SELECT T2.Zip FROM frpm \n",
    "AS T1 INNER JOIN schools AS T2 ON T1.CDSCode = T2.CDSCode WHERE T1.`District Name` = 'Fresno County Office of Education' \n",
    "AND T1.`Charter School (Y/N)` = 1\" Question: Consider the average difference between K-12 enrollment and 15-17 enrollment \n",
    "of schools that are locally funded, list the names and DOC type of schools which has a difference above this average. \n",
    "Executed SQL Query: \"SELECT T2.School, T2.DOC FROM frpm AS T1 INNER JOIN schools AS T2 ON T1.CDSCode = T2.CDSCode \n",
    "WHERE T2.FundingType = 'Locally funded' AND (T1.`Enrollment (K-12)` - T1.`Enrollment (Ages 5-17)`) > \n",
    "(SELECT AVG(T3.`Enrollment (K-12)` - T3.`Enrollment (Ages 5-17)`) FROM frpm AS T3 INNER JOIN schools AS T4 ON T3.CDSCode = \n",
    "T4.CDSCode WHERE T4.FundingType = 'Locally funded')\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = AgentsForAmazonBedrock()\n",
    "\n",
    "text2sql_agent = agents.create_agent(\n",
    "    agent_name,\n",
    "    agent_description,\n",
    "    agent_instruction,\n",
    "    agent_foundation_model,\n",
    "    code_interpretation=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "text2sql_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2sql_agent_id = text2sql_agent[0]\n",
    "text2sql_agent_arn = f\"arn:aws:bedrock:{region}:{account_id}:agent/{text2sql_agent_id}\"\n",
    "\n",
    "text2sql_agent_id, text2sql_agent_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_schema_string = '''{\n",
    "    \"openapi\": \"3.0.1\",\n",
    "    \"info\": {\n",
    "      \"title\": \"Database schema look up and query APIs\",\n",
    "      \"version\": \"1.0.0\",\n",
    "      \"description\": \"APIs for looking up database table schemas and making queries to database tables.\"\n",
    "    },\n",
    "    \"paths\": {\n",
    "      \"/getschema\": {\n",
    "        \"get\": {\n",
    "          \"summary\": \"Get a list of all columns in the athena database\",\n",
    "          \"description\": \"Get the list of all columns in the athena database table. Return all the column information in database table.\",\n",
    "          \"operationId\": \"getschema\",\n",
    "          \"responses\": {\n",
    "            \"200\": {\n",
    "              \"description\": \"Gets the list of table names and their schemas in the database\",\n",
    "              \"content\": {\n",
    "                \"application/json\": {\n",
    "                  \"schema\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                      \"type\": \"object\",\n",
    "                      \"properties\": {\n",
    "                        \"Table\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"description\": \"The name of the table in the database.\"\n",
    "                        },\n",
    "                        \"Schema\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"description\": \"The schema of the table in the database. Contains all columns needed for making queries.\"\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"/queryathena\": {\n",
    "        \"get\": {\n",
    "          \"summary\": \"API to send query to the athena database table\",\n",
    "          \"description\": \"Send a query to the database table to retrieve information pertaining to the users question. The API takes in only one SQL query at a time, sends the SQL statement and returns the query results from the table. This API should be called for each SQL query to a database table.\",\n",
    "          \"operationId\": \"queryathena\",\n",
    "          \"parameters\": [\n",
    "            {\n",
    "              \"name\": \"query\",\n",
    "              \"in\": \"query\",\n",
    "              \"required\": true,\n",
    "              \"schema\": {\n",
    "                \"type\": \"string\"\n",
    "              },\n",
    "              \"description\": \"SQL statement to query database table.\"\n",
    "            }\n",
    "          ],\n",
    "          \"responses\": {\n",
    "            \"200\": {\n",
    "              \"description\": \"Query sent successfully\",\n",
    "              \"content\": {\n",
    "                \"application/json\": {\n",
    "                  \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                      \"responseBody\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The query response from the database.\"\n",
    "                      }\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"400\": {\n",
    "              \"description\": \"Bad request. One or more required fields are missing or invalid.\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  } '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_schema = {\"payload\": api_schema_string}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach Lambda function and create ActionGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2sql_lambda_function_name = \"text2sql\"\n",
    "text2sql_lambda_function_arn = f\"arn:aws:lambda:{region}:{account_id}:function:{text2sql_lambda_function_name}\"\n",
    "%store text2sql_lambda_function_name\n",
    "%store text2sql_lambda_function_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.add_action_group_with_lambda(\n",
    "    agent_name=agent_name,\n",
    "    lambda_function_name=text2sql_lambda_function_name,\n",
    "    source_code_file=\"lambda_function.py\",\n",
    "    agent_action_group_name=\"queryAthena\",\n",
    "    agent_action_group_description=\"Action for getting the database schema and querying with Athena\",\n",
    "    api_schema=api_schema,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add environment variable to lambda function\n",
    "\n",
    "# Create unique bucket name\n",
    "bucket_suffix = uuid.uuid4().hex[:6]\n",
    "bucket_name = f\"birdsql-results-{bucket_suffix}\"\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "s3 = boto3.resource('s3')\n",
    "    \n",
    "if region == 'us-east-1':\n",
    "    # For us-east-1, don't specify LocationConstraint\n",
    "    s3_client.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"Created query results bucket: {bucket_name}\")\n",
    "else:\n",
    "    s3_client.create_bucket(\n",
    "        Bucket=bucket_name,\n",
    "        CreateBucketConfiguration={'LocationConstraint': region}\n",
    "    )\n",
    "    print(f\"Created query results bucket: {bucket_name}\")\n",
    "\n",
    "# Update Lambda environment variables\n",
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "try:\n",
    "    # Get current configuration\n",
    "    response = lambda_client.get_function_configuration(FunctionName=text2sql_lambda_function_name)\n",
    "    current_env = response.get('Environment', {}).get('Variables', {})\n",
    "    \n",
    "    # Add new environment variable\n",
    "    current_env['BUCKET_NAME'] = bucket_name\n",
    "    \n",
    "    # Update Lambda configuration\n",
    "    lambda_client.update_function_configuration(\n",
    "        FunctionName=text2sql_lambda_function_name,\n",
    "        Environment={\n",
    "            'Variables': current_env\n",
    "        }\n",
    "    )\n",
    "    print(f\"Added BUCKET_NAME environment variable to '{text2sql_lambda_function_name}' Lambda function\")\n",
    "except Exception as e:\n",
    "    print(f\"Error updating Lambda: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add resource based policy to Lambda function to allow agent to invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_client = boto3.client('lambda', region)\n",
    "\n",
    "# Define the resource policy statement\n",
    "policy_statement = {\n",
    "    \"Sid\": \"AllowBedrockAgentAccess\",\n",
    "    \"Effect\": \"Allow\",\n",
    "    \"Principal\": {\n",
    "        \"Service\": \"bedrock.amazonaws.com\"\n",
    "    },\n",
    "    \"Action\": \"lambda:InvokeFunction\",\n",
    "    \"Resource\": text2sql_lambda_function_arn,\n",
    "    \"Condition\": {\n",
    "        \"ArnEquals\": {\n",
    "            \"aws:SourceArn\": text2sql_agent_arn\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Get the current policy\n",
    "    response = lambda_client.get_policy(FunctionName=text2sql_lambda_function_arn)\n",
    "    current_policy = json.loads(response['Policy'])\n",
    "    \n",
    "    # Add the new statement to the existing policy\n",
    "    current_policy['Statement'].append(policy_statement)\n",
    "    \n",
    "except lambda_client.exceptions.ResourceNotFoundException:\n",
    "    # If there's no existing policy, create a new one\n",
    "    current_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [policy_statement]\n",
    "    }\n",
    "\n",
    "# Convert the policy to JSON string\n",
    "updated_policy = json.dumps(current_policy)\n",
    "\n",
    "# Add or update the resource policy\n",
    "response = lambda_client.add_permission(\n",
    "    FunctionName=text2sql_lambda_function_arn,\n",
    "    StatementId=\"AllowText2SQLAgentAccess\",\n",
    "    Action=\"lambda:InvokeFunction\",\n",
    "    Principal=\"bedrock.amazonaws.com\",\n",
    "    SourceArn=text2sql_agent_arn\n",
    ")\n",
    "\n",
    "print(\"Resource policy added successfully.\")\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add permissions to Lambda function execution role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clients\n",
    "iam_client = boto3.client('iam')\n",
    "lambda_client = boto3.client('lambda', region)\n",
    "\n",
    "# Get the function configuration\n",
    "response = lambda_client.get_function_configuration(FunctionName=text2sql_lambda_function_name)\n",
    "role_arn = response['Role']\n",
    "role_name = role_arn.split('/')[-1]\n",
    "\n",
    "# Policy ARNs to attach\n",
    "policy_arns = [\n",
    "    'arn:aws:iam::aws:policy/AmazonAthenaFullAccess',\n",
    "    'arn:aws:iam::aws:policy/AmazonS3FullAccess'\n",
    "]\n",
    "\n",
    "# Attach each policy\n",
    "for policy_arn in policy_arns:\n",
    "    try:\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn=policy_arn\n",
    "        )\n",
    "        print(f\"Successfully attached {policy_arn} to role {role_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error attaching {policy_arn}: {str(e)}\")\n",
    "\n",
    "# Verify attached policies\n",
    "try:\n",
    "    response = iam_client.list_attached_role_policies(RoleName=role_name)\n",
    "    print(\"\\nAttached policies:\")\n",
    "    for policy in response['AttachedPolicies']:\n",
    "        print(f\"- {policy['PolicyName']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error listing policies: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke Text2SQL Agent Test Alias to see that it answers question properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region)\n",
    "\n",
    "session_id:str = str(uuid.uuid1())\n",
    "\n",
    "# query = \"What is the highest eligible free rate for K-12 students in the schools in Alameda County?\"\n",
    "query = \"Please list the codes of the schools with a total enrollment of over 500\"\n",
    "response = bedrock_agent_runtime_client.invoke_agent(\n",
    "      inputText=query,\n",
    "      agentId=text2sql_agent_id,\n",
    "      agentAliasId=\"TSTALIASID\", \n",
    "      sessionId=session_id,\n",
    "      enableTrace=True, \n",
    "      endSession=False,\n",
    "      sessionState={}\n",
    ")\n",
    "\n",
    "print(\"Request sent to Agent\")\n",
    "print(\"====================\")\n",
    "print(\"Agent processing query now\")\n",
    "print(\"====================\")\n",
    "\n",
    "# Initialize an empty string to store the answer\n",
    "answer = \"\"\n",
    "\n",
    "# Iterate through the event stream\n",
    "for event in response['completion']:\n",
    "    # Check if the event is a 'chunk' event\n",
    "    if 'chunk' in event:\n",
    "        chunk_obj = event['chunk']\n",
    "        if 'bytes' in chunk_obj:\n",
    "            # Decode the bytes and append to the answer\n",
    "            chunk_data = chunk_obj['bytes'].decode('utf-8')\n",
    "            answer += chunk_data\n",
    "\n",
    "# Now 'answer' contains the full response from the agent\n",
    "print(\"Agent Answer: {}\".format(answer))\n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that agent has been tested via direct invoke, prepare it by creating an alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2sql_agent_alias_id, text2sql_agent_alias_arn = agents.create_agent_alias(\n",
    "    text2sql_agent[0], 'v1'\n",
    ")\n",
    "\n",
    "text2sql_agent_alias_id, text2sql_agent_alias_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input file for evaluation framework to evaluate agent's Text2SQL capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is the option to specify the number of questions to generate. \n",
    "\n",
    "#### Default is 10, set to -1 to run through all questions, or specify to any other desired number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_questions = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATHENA_RESULTS_BUCKET_NAME = os.environ.get('ATHENA_RESULTS_BUCKET_NAME')\n",
    "DATABASE_NAME = os.environ.get('DATABASE_NAME')\n",
    "\n",
    "ATHENA_RESULTS_BUCKET_NAME, DATABASE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run below cell to generate ground truth information for each question\n",
    "Please wait for all information to be generated before proceeding to next step\n",
    "Note: This script uses an LLM to generate a ground truth SQL query so not all questions will be able to have a ground truth, in that case the question is skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def run_query(query: str, athena_client):\n",
    "    \"\"\"\n",
    "    Run Athena query and return results as pandas DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = athena_client.start_query_execution(\n",
    "            QueryString=query,\n",
    "            QueryExecutionContext={\n",
    "                'Database': DATABASE_NAME\n",
    "            },\n",
    "            ResultConfiguration={\n",
    "                'OutputLocation': f's3://{ATHENA_RESULTS_BUCKET_NAME}/athena-results/'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        query_execution_id = response['QueryExecutionId']\n",
    "        \n",
    "        while True:\n",
    "            response = athena_client.get_query_execution(QueryExecutionId=query_execution_id)\n",
    "            state = response['QueryExecution']['Status']['State']\n",
    "            \n",
    "            if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
    "                break\n",
    "                \n",
    "            time.sleep(1)\n",
    "            \n",
    "        if state == 'SUCCEEDED':\n",
    "            response = athena_client.get_query_results(QueryExecutionId=query_execution_id)\n",
    "            # Process data\n",
    "            results = []\n",
    "            for row in response['ResultSet']['Rows'][1:]:  # Skip header row\n",
    "                for field in row['Data']:\n",
    "                    value = field.get('VarCharValue', '')\n",
    "                    \n",
    "                    results.append(str(value))\n",
    "            \n",
    "            # Join results with commas\n",
    "            return ', '.join(results)\n",
    "        else:\n",
    "            print(f\"Generated query failed with state: {state}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error running query: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_ground_truth_answer(question_id: int, question: str, sql_query: str, \n",
    "                               sql_context: str, query_results: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Generate ground truth answer using AWS Bedrock based on question and query results\n",
    "    \"\"\"\n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name='bedrock-runtime'\n",
    "    )\n",
    "        \n",
    "    # Construct prompt for Bedrock\n",
    "    prompt = f\"\"\"You are generating ground truth answers that will be used to evaluate the factual correctness of Text2SQL agent responses.\n",
    "\n",
    "Question: {question}\n",
    "Query Results: {query_results}\n",
    "\n",
    "Generate a natural language answer that:\n",
    "1. States all numerical values and facts from the query results explicitly\n",
    "2. Uses consistent formatting for numbers (maintain exact precision from results)\n",
    "3. Includes all relevant values if multiple results are returned\n",
    "4. States the answer in a clear, declarative way that directly addresses the question\n",
    "5. Avoids additional interpretations or information not present in the query results\n",
    "\n",
    "Remember:\n",
    "- Focus only on the facts present in the query results\n",
    "- Use the exact numbers shown in the results\n",
    "- Structure the answer to make fact-checking straightforward\n",
    "- Be explicit about any percentages, counts, or measurements\n",
    "- Make sure every number in the query results is mentioned in your answer\n",
    "\n",
    "Your answer should be easy to compare with other responses for factual accuracy.\"\"\"\n",
    "\n",
    "    # Create request body for Claude model\n",
    "    body = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "            }\n",
    "        ],\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        # Call Bedrock\n",
    "\n",
    "        response = None\n",
    "\n",
    "        # Use cross-region inference profile\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId='us.anthropic.claude-3-5-sonnet-20241022-v2:0',  # or your preferred model\n",
    "            body=body\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        response_body = json.loads(response['body'].read())\n",
    "        answer = response_body['content'][0]['text']\n",
    "        \n",
    "        # Format the response in the required structure\n",
    "        formatted_response = {\n",
    "            \"question_id\": question_id,\n",
    "            \"question\": question,\n",
    "            \"question_type\": \"TEXT2SQL\",\n",
    "            \"ground_truth\": {\n",
    "                \"ground_truth_sql_query\": sql_query,\n",
    "                \"ground_truth_sql_context\": sql_context,\n",
    "                \"ground_truth_query_result\": query_results,\n",
    "                \"ground_truth_answer\": answer\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return formatted_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer: {e}\")\n",
    "        return None\n",
    "\n",
    "        \n",
    "def get_schema(athena_client):\n",
    "    \"\"\"\n",
    "    Get schema information for all tables in Athena databases\n",
    "    \"\"\"\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "            table_name,\n",
    "            column_name,\n",
    "            data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = '{DATABASE_NAME}'\n",
    "        ORDER BY table_name, ordinal_position;\n",
    "        \"\"\"\n",
    "        \n",
    "    try:\n",
    "        # Start query execution\n",
    "        response = athena_client.start_query_execution(\n",
    "            QueryString=sql,\n",
    "            QueryExecutionContext={\n",
    "                'Database': DATABASE_NAME\n",
    "            }\n",
    "        )\n",
    "            \n",
    "        query_execution_id = response['QueryExecutionId']\n",
    "            \n",
    "        def wait_for_query_completion(query_execution_id):\n",
    "            while True:\n",
    "                response = athena_client.get_query_execution(\n",
    "                    QueryExecutionId=query_execution_id\n",
    "                )\n",
    "                state = response['QueryExecution']['Status']['State']\n",
    "                \n",
    "                if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
    "                    return state\n",
    "                    \n",
    "                time.sleep(2)\n",
    "            \n",
    "        # Wait for query completion\n",
    "        state = wait_for_query_completion(query_execution_id)\n",
    "\n",
    "        if state == 'SUCCEEDED':\n",
    "            # Get query results\n",
    "            results = athena_client.get_query_results(\n",
    "                QueryExecutionId=query_execution_id\n",
    "            )\n",
    "            # Assuming you have a database connection and cursor setup\n",
    "            # cursor.execute(sql)\n",
    "            # results = cursor.fetchall()\n",
    "            \n",
    "            database_structure = []\n",
    "            table_dict = {}\n",
    "\n",
    "            # Skip the header row\n",
    "            rows = results['ResultSet']['Rows'][1:]\n",
    "\n",
    "            for row in rows:\n",
    "                # Extract values from the Data structure\n",
    "                table_name = row['Data'][0]['VarCharValue']\n",
    "                column_name = row['Data'][1]['VarCharValue']\n",
    "                data_type = row['Data'][2]['VarCharValue']\n",
    "                \n",
    "                # Initialize table if not exists\n",
    "                if table_name not in table_dict:\n",
    "                    table_dict[table_name] = []\n",
    "                \n",
    "                # Append column information\n",
    "                table_dict[table_name].append((column_name, data_type))\n",
    "\n",
    "            # Convert to the desired format\n",
    "            for table_name, columns in table_dict.items():\n",
    "                database_structure.append({\n",
    "                    \"table_name\": table_name,\n",
    "                    \"columns\": columns\n",
    "                })\n",
    "\n",
    "            return database_structure\n",
    "\n",
    "        else:\n",
    "            raise Exception(f\"Query to get schema failed with state: {state}\")\n",
    "    except Exception as e:\n",
    "            print(f\"Error getting schema: {e}\")\n",
    "            raise\n",
    "\n",
    "def generate_dataset(input_file: str, output_file: str, athena_client, num_questions):\n",
    "    \"\"\"\n",
    "    Generate dataset with ground truth answers in trajectory format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read input file\n",
    "        with open(input_file, 'r') as f:\n",
    "            questions_data = json.load(f)\n",
    "        \n",
    "        # Initialize trajectories dictionary\n",
    "        trajectories = {}\n",
    "\n",
    "        # Keep track of number of trajectories created\n",
    "        num_trajectories = 0\n",
    "        \n",
    "        # Process each question\n",
    "        for idx, item in enumerate(questions_data):\n",
    "\n",
    "            if num_questions != -1:\n",
    "                if num_trajectories == num_questions:\n",
    "                    break\n",
    "       \n",
    "            question_id = item.get('question_id', 0)\n",
    "            question = item['question']\n",
    "            sql_query = item['SQL']\n",
    "            \n",
    "            print(f\"\\nProcessing question {question_id}: {question}\")\n",
    "            \n",
    "            # Get table schema\n",
    "            sql_context = get_schema(athena_client)\n",
    "            # Run query\n",
    "            query_results = run_query(sql_query.replace('`','\"'), athena_client)\n",
    "            if query_results is not None:\n",
    "                # Generate answer with formatted response\n",
    "                response = generate_ground_truth_answer(\n",
    "                    question_id=question_id,\n",
    "                    question=question,\n",
    "                    sql_query=sql_query,\n",
    "                    sql_context=str(sql_context),\n",
    "                    query_results=query_results\n",
    "                )\n",
    "                \n",
    "                if response:\n",
    "                    # Increment number of trajectories\n",
    "                    num_trajectories += 1\n",
    "                    \n",
    "                    # Create trajectory key\n",
    "                    trajectory_key = f\"Trajectory{num_trajectories}\"\n",
    "                    \n",
    "                    # Format the response for this trajectory\n",
    "                    trajectory_response = [response]\n",
    "                    \n",
    "                    # Add to trajectories dictionary\n",
    "                    trajectories[trajectory_key] = trajectory_response\n",
    "                    print(f\"Generated ground truth for question {question_id}\")\n",
    "            else:\n",
    "                # Don't increment number of trajectories\n",
    "                print(\"Ground truth unable to be generated for this question, skipping\")\n",
    "                continue\n",
    "            \n",
    "        # Write results to output file\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(trajectories, f, indent=2)\n",
    "            \n",
    "        print(f\"\\nProcessed {len(trajectories)} questions. Results saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating dataset: {e}\")\n",
    "\n",
    "INPUT_FILE = \"birdsql_data.json\"\n",
    "OUTPUT_FILE = \"text2sql_data_file_auto.json\"\n",
    "\n",
    "athena_client = boto3.client('athena')\n",
    "\n",
    "generate_dataset(INPUT_FILE, OUTPUT_FILE,athena_client, num_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create config.env that evaluation tool needs\n",
    "Note: Input Langfuse host and keys into the variables below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = f\"\"\"\n",
    "\n",
    "AGENT_ID=\"{text2sql_agent_id}\"\n",
    "AGENT_ALIAS_ID=\"{text2sql_agent_alias_id}\"\n",
    "\n",
    "DATA_FILE_PATH=\"blog_sample_agents/2-Sample-text2sql-agent/text2sql_data_file_auto.json\"\n",
    "\n",
    "LANGFUSE_PUBLIC_KEY=\"FILL IN\"\n",
    "LANGFUSE_SECRET_KEY=\"FILL IN\"\n",
    "LANGFUSE_HOST=\"FILL IN\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from string import Template\n",
    "\n",
    "# Set the correct paths relative to current location\n",
    "base_dir = os.path.dirname(os.path.dirname(os.getcwd()))  # Go up two levels\n",
    "template_file_path = os.path.join(base_dir, 'config.env.tpl')\n",
    "config_file_path = os.path.join(base_dir, 'config.env')\n",
    "\n",
    "# Read the template file from the Bedrock Agent Evaluation Framework\n",
    "with open(template_file_path, 'r') as template_file:\n",
    "    template_content = template_file.read()\n",
    "\n",
    "\n",
    "# Convert template content and user input into dictionaries\n",
    "def parse_env_content(content):\n",
    "    env_dict = {}\n",
    "    for line in content.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line and not line.startswith('#'):\n",
    "            if '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                env_dict[key.strip()] = value.strip()\n",
    "    return env_dict\n",
    "\n",
    "template_dict = parse_env_content(template_content)\n",
    "user_dict = parse_env_content(user_input)\n",
    "\n",
    "# Merge dictionaries, with user input taking precedence\n",
    "final_dict = {**template_dict, **user_dict}\n",
    "\n",
    "# Create the config.env content\n",
    "config_content = \"\"\n",
    "for key, value in final_dict.items():\n",
    "    config_content += f\"{key}={value}\\n\"\n",
    "\n",
    "# Write to config.env file in the correct folder\n",
    "with open(config_file_path, 'w') as config_file:\n",
    "    config_file.write(config_content)\n",
    "\n",
    "print(f\"config.env file has been created successfully in amazon-bedrock-agent-evaluation-framework!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "os.chdir(\"../..\")\n",
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Bedrock Agent Evaluation Framework on the newly created sample Text2SQL agent\n",
    "Note: For some questions, the Text2SQL agent may not generate an executable query, in that case an error trace will show in Langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation tool against data file\n",
    "!python3 driver.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
